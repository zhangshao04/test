{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "A = torch.zeros((2,3,4))\n",
    "print(A)\n",
    "A.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2,3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0160,  0.9338, -1.5487,  1.8655],\n",
       "        [ 0.8787, -1.1745, -0.5480,  1.0982],\n",
       "        [ 0.4188, -1.1697,  0.2973,  0.8070]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.,  7.],\n",
       "       [ 8.,  9., 10., 11.],\n",
       "       [ 2.,  1.,  4.,  3.],\n",
       "       [ 1.,  2.,  3.,  4.],\n",
       "       [ 4.,  3.,  2.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12).reshape((3,4))\n",
    "Y = torch.tensor([[2.0,1,4,3],[1,2,3,4],[4,3,2,1]])\n",
    "A = torch.cat((X,Y),dim = 0)\n",
    "B = torch.cat((X,Y),dim = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3,1))\n",
    "b = torch.arange(2).reshape((1,2))\n",
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a为3×1的矩阵，b为1×2的矩阵，执行运算操作时a会复制列，b会复制行，再进行按元素运算，使结果输出一个3×2的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 20]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  6,  6,  6],\n",
       "        [ 6,  6,  6,  6],\n",
       "        [ 8,  9, 10, 20]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12).reshape((3,4))\n",
    "X[2,3] = 20\n",
    "print(X)\n",
    "X[0:2,:] = 6\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12).reshape((3,4))\n",
    "Y = torch.tensor([[2.0,1,4,3],[1,2,3,4],[4,3,2,1]])\n",
    "before = id(Y)\n",
    "Y += X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Y = Y + X会分配不必要的内存，而使用Y += X 不会(或者使用切片的操作方式，Y[:] = Y + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5000])\n",
      "3.5 3.5 3\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "print(a)\n",
    "x = a.item()\n",
    "b = float(a)\n",
    "c = int(a)\n",
    "print(x,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..','data'),exist_ok= True)\n",
    "data_file = os.path.join('..','data','house_tiny.csv')\n",
    "with open(data_file,'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')\n",
    "    f.write('NA,Pave,127500\\n')\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAN即为数据缺失值(待处理)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n",
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    }
   ],
   "source": [
    "inputs,outputs = data.iloc[:,0:2],data.iloc[:,2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(data)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0           1          0\n",
      "1       2.0           0          1\n",
      "2       4.0           0          1\n",
      "3       3.0           0          1\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs,dummy_na= True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None)\n",
    "prefix：str, list of str, 或 dict of str, 默认为 None\n",
    "用于追加DataFrame列名称的字符串。\n",
    " \n",
    "prefix_sep：str, 默认为 ‘_’\n",
    "如果附加前缀，则使用分隔符/分隔符。或者像这样传递列表或字典prefix。\n",
    " \n",
    "dummy_na：bool, 默认为 False\n",
    "如果忽略False NaN。\n",
    " \n",
    "columns：list-like, 默认为 None\n",
    "要编码的DataFrame中的列名。如果columns为None，则所有具有的列object或者categorydtype将被转换。\n",
    " \n",
    "sparse：bool, 默认为 False\n",
    "dummy-encoded列是否应由a支持SparseArray(True)或常规NumPy数组(False)。\n",
    " \n",
    "drop_first：bool, 默认为 False\n",
    "是否通过删除第一个级别从k个分类级别中获取k-1个虚拟对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 1., 0.],\n",
      "        [2., 0., 1.],\n",
      "        [4., 0., 1.],\n",
      "        [3., 0., 1.]], dtype=torch.float64)\n",
      "tensor([127500., 106000., 178100., 140000.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(inputs.to_numpy(dtype=float))\n",
    "Y = torch.tensor(outputs.to_numpy(dtype=float))\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将inputs,outputs全部转换为张量格式，方便使用函数进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5, 10, 15],\n",
       "        [ 1,  6, 11, 16],\n",
       "        [ 2,  7, 12, 17],\n",
       "        [ 3,  8, 13, 18],\n",
       "        [ 4,  9, 14, 19]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "A = torch.arange(20).reshape((4,5))\n",
    "print(A)\n",
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "A = torch.arange(20,dtype=torch.float32).reshape(5,4)\n",
    "B = A.clone()\n",
    "print(A)\n",
    "A * B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相同形状矩阵进行二元运算则按元素进行操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "tensor([[[ 2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9],\n",
      "         [10, 11, 12, 13]],\n",
      "\n",
      "        [[14, 15, 16, 17],\n",
      "         [18, 19, 20, 21],\n",
      "         [22, 23, 24, 25]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = 2\n",
    "X = torch.arange(24).reshape(2,3,4)\n",
    "print(X)\n",
    "print(a + X)\n",
    "(a + X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "tensor(66.)\n",
      "tensor(66.)\n",
      "tensor([12., 15., 18., 21.])\n",
      "tensor([ 6., 22., 38.])\n",
      "tensor(5.5000)\n",
      "tensor([4., 5., 6., 7.])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(12,dtype=torch.float32).reshape(3,4)\n",
    "print(A)\n",
    "print(A.sum())\n",
    "B = A.sum()\n",
    "print(B)\n",
    "C = A.sum(axis = 0)\n",
    "print(C)\n",
    "D = A.sum(axis = 1)\n",
    "print(D)\n",
    "print(A.mean())\n",
    "print(A.mean(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum(axis = <轴>)为降维求和,使用后矩阵被降维成一个张量。用mean(axis = <轴>)求平均值矩阵内的元素必须为浮点型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "tensor([[12., 15., 18., 21.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  6.,  8., 10.],\n",
       "        [12., 15., 18., 21.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12,dtype=torch.float32).reshape(3,4)\n",
    "print(A)\n",
    "sum_A = A.sum(axis = 0,keepdim= True)\n",
    "print(sum_A)\n",
    "A.cumsum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum(axis = <轴数>，keepdim = true)为非降维求和，矩阵求和后任然为一个矩阵。cumsum()函数不会沿任何轴降低矩阵的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.])\n",
      "tensor([1., 1., 1., 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(4,dtype=torch.float32)\n",
    "print(X)\n",
    "y = torch.ones(4,dtype=torch.float32)\n",
    "print(Y)\n",
    "torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "tensor([0., 1., 2., 3.])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([ 14.,  38.,  62.,  86., 110.])\n",
      "tensor([[ 6.],\n",
      "        [22.],\n",
      "        [38.],\n",
      "        [54.],\n",
      "        [70.]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(20,dtype=torch.float32).reshape(5,4)\n",
    "x = torch.arange(4,dtype=torch.float32)\n",
    "B = torch.ones(4,1)\n",
    "print(A)\n",
    "print(x)\n",
    "print(B)\n",
    "print(torch.mv(A,x))\n",
    "print(torch.mm(A,B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.mv()为矩阵×向量，结果为一个向量。torch.mm()为矩阵×矩阵，结果为一个矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.0711)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0,-4.0,5.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.norm()求矩阵的Frobenius范数（即矩阵元素和的平方根）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
